### sales.sql
In this project, I designed and implemented a relational database schema for sales data analysis. I created a sales fact table and associated dimension tables (products and stores). I inserted dummy data into the tables and explored the data to gain insights. I performed simple queries to retrieve product and store information, and more complex queries using joins, groupings, and aggregations to analyze sales revenue by product category and store location. Additionally, I created views for commonly used queries to streamline future analysis tasks.

### sqliteDataMgmt.py
In this Python script I demonstrates efficient data management with SQLite databases. I showcase my skills in creating databases, loading data from CSV files, appending new data, executing queries, and displaying query results. The script includes modular functions for each task, promoting code reusability and maintainability.

### top25movies.py
In this Python script, I demonstrate my proficiency in web scraping techniques by extracting data from a webpage listing the top 100 highly-ranked films. Leveraging the BeautifulSoup library, I parse the HTML content to retrieve movie titles, release years, and their rankings. The extracted data is then stored in both a CSV file and a SQLite database, showcasing my skills in data manipulation and database management.

### etl_project_gdp.py
In this Python script, I perform Extract, Transform and Load operations on data related to countries' Gross Domestic Product (GDP). Leveraging BeautifulSoup and Pandas, I extract GDP data from a webpage listing countries by nominal GDP. The extracted data is then transformed to clean and format it appropriately, including converting GDP values to billions of USD. Finally, I load the cleaned data into both a CSV file and a SQLite database for further analysis. The script also includes functionality to execute SQL queries on the database, providing insights into the dataset. This project showcases my skills in web scraping, data manipulation, and database management, making it a valuable addition to my portfolio as a data engineer.

### airflow_etl.py
In this Python script i use Apache Airflow to Extract, Transform, and Load toll data from different sources. The DAG consists of tasks to unzip data files, extract information from CSV, TSV, and fixed-width files, consolidate the data, and apply transformations. Each task is orchestrated to run sequentially, ensuring a streamlined ETL workflow. This project showcases proficiency in workflow orchestration, data processing, and automation using Apache Airflow.



